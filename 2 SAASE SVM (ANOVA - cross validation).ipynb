{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a3525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import time\n",
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37381b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "def load_data():\n",
    "    df = pd.read_csv('SAASE features.csv')\n",
    "    target_name = 'Emotion'\n",
    "    \"\"\"make code line as note if you want to include it in the experiment\"\"\"\n",
    "    # observed emotion\n",
    "    #df.drop(df[df['Emotion'] == \"neutral\"].index, inplace = True)\n",
    "    #df.drop(df[df['Emotion'] == \"angry\"].index, inplace = True)\n",
    "    #df.drop(df[df['Emotion'] == \"happy\"].index, inplace = True)\n",
    "    df.drop(df[df['Emotion'] == \"sad\"].index, inplace = True)\n",
    "    \n",
    "    # observed gender\n",
    "    #df.drop(df[df['gender'] == \"male\"].index, inplace = True)\n",
    "    df.drop(df[df['gender'] == \"female\"].index, inplace = True)\n",
    "    \n",
    "    # remove unrelated colunms (This line is fixed and cannot be hide as a note)\n",
    "    df.drop(['speaker','gender','voiceID'], inplace=True, axis=1)\n",
    "    \n",
    "    # speech features\n",
    "    \"\"\"make code line as note if you want to include it in the features set of the experiment\"\"\"\n",
    "    # Prosodic 1\n",
    "    #df.drop(['Pitch mean', 'Pitch stdev', 'Pitch max', 'Pitch min', 'Pitch range','Intensity mean', 'Intensity stdev', 'Intensity max', 'Intensity min', 'Intensity range','Jitter PCA','shimmer PCA'], inplace=True, axis=1)\n",
    "    \n",
    "    #Formants\n",
    "    #df.drop(['Formant 1 mean','Formant 1 stdev','Formant 2 mean','Formant 2 stdev','Formant 3 mean','Formant 3 stdev'], inplace=True, axis=1)\n",
    "    \n",
    "    # MFCC\n",
    "    #df.drop(['MFCC 1','MFCC 2','MFCC 3','MFCC 4','MFCC 5','MFCC 6','MFCC 7','MFCC 8','MFCC 9','MFCC 10','MFCC 11','MFCC 12','MFCC 13'], inplace=True, axis=1)    \n",
    "   \n",
    "    #LTAS\n",
    "    #df.drop(['LTAS mean', 'LTAS stdev', 'LTAS max', 'LTAS min', 'LTAS range', 'LTAS slope'], inplace=True, axis=1)\n",
    "    \n",
    "    # Wavelet\n",
    "    #df.drop(['Ed5','Ed4', 'Ed3', 'Ed2', 'Ed1', 'Ea', 'wentropy'], inplace=True, axis=1)\n",
    "    \n",
    "    # Prosodic 2\n",
    "    #df.drop(['HNR', 'Duration','ZCR'], inplace=True, axis=1)\n",
    "    \n",
    "    # LPC\n",
    "    #df.drop(['LPC'], inplace=True, axis=1)\n",
    "    \n",
    "    y = df[target_name]\n",
    "    x = df.drop(target_name, axis=1)\n",
    "    \n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87442fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select #k of top features based on p-value\n",
    "def select_features(x, y, k):\n",
    "    # configure to select all features\n",
    "    fs = SelectKBest(score_func=f_classif, k=k)\n",
    "    # learn relationship from training data\n",
    "    fs.fit(x, y)\n",
    "    # transform train input data\n",
    "    x_fs = fs.transform(x)   \n",
    "    return x_fs, fs\n",
    "\n",
    "\n",
    "#draw confusion matrix\n",
    "def plot_confusion_matrix(matrix, sorted_labels : list):    \n",
    "    plt.figure(figsize=(12.8,6))\n",
    "    sns.heatmap(matrix, annot=True, xticklabels=sorted_labels, yticklabels=sorted_labels, cmap=\"Blues\", fmt=\"g\")\n",
    "    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d469712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_predict(model, x, y):\n",
    "    kf= StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    predicted_targets = np.array([]) # predicted\n",
    "    actual_targets = np.array([]) # y_test\n",
    "    for train_index, test_index in kf.split(x,y):  \n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model.fit(x_train, y_train)\n",
    "        \n",
    "        predicted_labels = model.predict(x_test)\n",
    "        predicted_targets = np.append(predicted_targets, predicted_labels)\n",
    "        actual_targets = np.append(actual_targets, y_test)\n",
    "\n",
    "    return actual_targets, predicted_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12dc3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tic = time.perf_counter()\n",
    "#loading_data\n",
    "x,y = load_data()\n",
    "# define number of features to evaluate\n",
    "num_features = [i+1 for i in range(x.shape[1])] #number of all features\n",
    "num_features_n = [42] #define specific number of features\n",
    "\n",
    "for k in num_features_n:\n",
    "    ti = time.perf_counter()\n",
    "    # feature selection\n",
    "    x_fs, fs = select_features(x, y, k)\n",
    "    \n",
    "    # SVM with linear kernel\n",
    "    model = SVC(kernel = 'linear', C = 1)\n",
    "        \n",
    "    # evaluate the model\n",
    "    #x = x.to_numpy()\n",
    "    y1 = y.to_numpy()\n",
    "    y_test, predicted = cross_val_predict(model, x_fs, y1)\n",
    "    \n",
    "    # calculate evaluation parameters \n",
    "    accuracy = accuracy_score(y_test, predicted)\n",
    "    conf_matrix = confusion_matrix(y_test, predicted)\n",
    "    precision = precision_score(y_test, predicted, average= None)\n",
    "    recall = recall_score(y_test, predicted, average= None)\n",
    "    \n",
    "    # print results\n",
    "    print(\"Both\")\n",
    "    print(\"Avg accuracy: \", accuracy *100)\n",
    "    print(\"Avg precision: \", precision)\n",
    "    print(\"Avg recall: \", recall)\n",
    "\n",
    "    plot_confusion_matrix(conf_matrix, [\"Anger\", \"Happy\", \"neutral\", \"sad\"])\n",
    "\n",
    "    to = time.perf_counter()\n",
    "    print(f\"Running time: {(to - ti)/60:0.4f} minutes\")\n",
    "toc = time.perf_counter()\n",
    "print(f\"Running time: {(toc - tic)/60:0.4f} minutes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
